{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text generation with an RNN"
      ],
      "metadata": {
        "id": "Srlq6VGJ7qhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "_A6Trbqc7mJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview:\n",
        "This code implements a Recurrent Neural Network (RNN) for text generation using TensorFlow. The model is trained on a Shakespearean text and is designed to generate text character by character. The code consists of several parts:\n",
        "\n",
        "1. Data Preparation: The Shakespearean text is loaded, and a vocabulary of unique characters is created. The text is then split into sequences of a defined length.\n",
        "\n",
        "2. Model Definition: An RNN-based model is defined using TensorFlow's tf.keras framework. It consists of an embedding layer, a GRU (Gated Recurrent Unit) layer, and a dense output layer.\n",
        "\n",
        "3. Training: The model is trained using the prepared dataset of sequences. Training checkpoints are saved to resume training or generate text later.\n",
        "\n",
        "4. Text Generation: After training, a sampling function is defined to generate text character by character using the trained model."
      ],
      "metadata": {
        "id": "zxM8QI079a6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports the necessary libraries: TensorFlow, NumPy, and modules for file operations (os) and timing (time)."
      ],
      "metadata": {
        "id": "ZSdF8HXP9uF8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIKxmVKRqsDP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloads the Shakespearean text from the specified URL and saves it to the path_to_file location."
      ],
      "metadata": {
        "id": "21qidOTq9wYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D9LxJAOq2VK",
        "outputId": "e02f1a8b-d561-4972-d03c-7bbe060bddf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 1s 1us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Reads the content of the downloaded file as bytes ('rb' mode) and decodes it using UTF-8 encoding to obtain a text string.\n",
        "2. Prints the length of the text in characters.\n",
        "3. Prints the first 250 characters of the text."
      ],
      "metadata": {
        "id": "j9R3UfPk91zl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXVbrVuPq_LQ",
        "outputId": "a3360b1b-5d88-4638-bf19-2d991846d378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGnXrbhGrDXS",
        "outputId": "e152dc02-41a5-4b95-d229-b99cb10925e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creates a sorted set of unique characters present in the text. Prints the number of unique characters in the vocabulary."
      ],
      "metadata": {
        "id": "Muabpsxr-Ijf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzkKiH4crFhV",
        "outputId": "924bb4bf-bd2c-4499-ec9b-34db69eb10bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defines a list of example texts. Uses TensorFlow's unicode_split function to split the example texts into individual characters, encoded using UTF-8."
      ],
      "metadata": {
        "id": "NTvHt3Ip-OG-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB5w2oJ1rIFK",
        "outputId": "5893af39-1a84-4aa3-d353-2a0f4b7c9a2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creates a StringLookup layer that maps characters to their corresponding integer IDs using the provided vocabulary. mask_token=None indicates that there's no masking token used."
      ],
      "metadata": {
        "id": "1p67sz30-VE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5f1zYLArL-i"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Converts the character sequences to corresponding integer IDs using the ids_from_chars layer."
      ],
      "metadata": {
        "id": "sMtMqLjv-cbw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNPNOs46rP7u",
        "outputId": "04d3f1da-aa96-4d3b-d7cd-9700a92bf34d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creates another StringLookup layer for mapping integer IDs back to characters. Retrieves the vocabulary from the ids_from_chars layer using get_vocabulary(). invert=True ensures the mapping goes from IDs to characters."
      ],
      "metadata": {
        "id": "FJOiVCDC-gTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsi6-oj1rSW0"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Converts the integer IDs back to character sequences using the chars_from_ids layer."
      ],
      "metadata": {
        "id": "C7zAXmTa-nry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ2kmpt3rUMV",
        "outputId": "bb72283a-b78a-498a-fa71-e27e054264f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Joins the character sequences back into strings using reduce_join. The resulting strings are converted to NumPy arrays."
      ],
      "metadata": {
        "id": "XOoDqMeN-qay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHqe3HbHrVKL",
        "outputId": "d0195cfa-140f-4f0f-fa74-98d51d2d45ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defines a function text_from_ids that converts integer ID sequences to text strings. Uses the ids_from_chars layer to convert the entire text into integer ID sequences."
      ],
      "metadata": {
        "id": "Og4ugsjU-zkM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nru13CorW88"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC7GFK0_raFk",
        "outputId": "a0672e5d-7c1d-476a-9a45-d35150c86fb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaKlLxqKrejV"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svuv7CvHrgHo",
        "outputId": "a1b25a28-372a-4a9b-8f4e-f6f1ebc7f481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05heds_RrhmK"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ632-_GrlZ8",
        "outputId": "0b8e1236-108d-43b4-b4bc-3b3b2d5acc08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upl7teAdrnRE",
        "outputId": "89628925-fdd1-4bf9-b61f-25ef163238f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX8y7Gv9roBh"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdlTnbLirp5p",
        "outputId": "57b1c2e8-d092-4081-ab78-680e6f719988"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQbYoDNjrrkb"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6FNZhyUrtJ3",
        "outputId": "aaac2d57-dbaf-4fc5-9ab8-0c9303dbf63b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVgmH40brucR",
        "outputId": "e89149b8-e72c-4b34-e06f-005452a3b430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEW0bVh7rwl0"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXexZA6sryy_"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE3nzxqDr3xW"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SffVveZar6ds",
        "outputId": "9e4c349d-b70b-4460-b1e6-b7ec56fbb1d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdRp1idYr8aG",
        "outputId": "a1204e0a-e4c9-4de9-d8d4-2a6ff24b6fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,022,850\n",
            "Trainable params: 4,022,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryuxLYB0r9mo"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJH39bL0sAFx",
        "outputId": "21b8c44a-d435-4cec-cb06-860d3e99b510"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([61, 41, 50, 40, 31, 49, 34, 11,  4, 13, 38, 11, 13, 55,  8, 57, 15,\n",
              "       36, 63, 40, 53, 49, 32, 20, 20, 48,  3, 56,  8, 26, 16, 35, 25, 61,\n",
              "        5, 49, 20, 18, 19,  8, 28, 41, 55, 28, 37, 16, 64, 31, 16, 65, 29,\n",
              "       33, 25, 50, 32, 15, 41, 44, 15,  1, 26, 57, 48, 65, 48, 23, 45, 20,\n",
              "       60, 29, 19,  2, 24, 29,  2, 36,  1, 48, 47, 43, 18, 50, 62, 61, 18,\n",
              "       60, 26, 32, 26, 33, 56, 15, 45, 62, 53, 20, 30, 21,  6, 64])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtJkVwPgsBZT",
        "outputId": "91ddbdbd-67d4-4ce1-b191-85d0274f1a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b\"lting o'er his prey,\\nAnd so he comes, to rend his limbs asunder.\\nAh, gentle Clifford, kill me with t\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"vbkaRjU:$?Y:?p-rBWxanjSGGi!q-MCVLv&jGEF-ObpOXCyRCzPTLkSBbeB\\nMriziJfGuPF KP W\\nihdEkwvEuMSMTqBfwnGQH'y\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfzCEdyysGt5"
      },
      "outputs": [],
      "source": [
        "  loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18mW2WiasHsy",
        "outputId": "a2b37f60-9a61-433a-f89a-f67fcd8039a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1907325, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXLwedPDsJH5",
        "outputId": "3a73174c-cc26-4156-d402-b3e1be2c1bb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66.07117"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxmRjgjqsLD5"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjfP9_cUsMtJ"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkW265h2sQCX"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGSxRYuVsRiW",
        "outputId": "b50c3f2e-93c1-44f3-eae0-8e4d22ff2982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 903s 5s/step - loss: 2.7003\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 863s 5s/step - loss: 1.9814\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 856s 5s/step - loss: 1.7045\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 860s 5s/step - loss: 1.5448\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 857s 5s/step - loss: 1.4467\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 860s 5s/step - loss: 1.3788\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 885s 5s/step - loss: 1.3272\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 874s 5s/step - loss: 1.2822\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 855s 5s/step - loss: 1.2423\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 863s 5s/step - loss: 1.2017\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 852s 5s/step - loss: 1.1619\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 865s 5s/step - loss: 1.1201\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 898s 5s/step - loss: 1.0757\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 910s 5s/step - loss: 1.0293\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 905s 5s/step - loss: 0.9808\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 914s 5s/step - loss: 0.9287\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 901s 5s/step - loss: 0.8756\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 858s 5s/step - loss: 0.8225\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 853s 5s/step - loss: 0.7711\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 851s 5s/step - loss: 0.7238\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP8C8HaRsSbS"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HccjljGssazX"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF3guqfPsc3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b217b7e-9d6c-4bae-bd8c-d34f0df36fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Sir, if you'ld Isabel.\n",
            "Shall tell the present pamberful cook her, have\n",
            "Simpled the fairous little advantage, good and loving friar,\n",
            "To strike him down again to Plaise my house.\n",
            "Yet that a wise barr life-strength wrong'd\n",
            "These hard-head-eddeners.\n",
            "\n",
            "BENVOLIO:\n",
            "A horse, and many a town in good lies in land\n",
            "And find his charger of thy pares.\n",
            "\n",
            "LUCIO:\n",
            "What men of worshipful senses you have done a brother?\n",
            "\n",
            "JULIET:\n",
            "Withdraw yourselves again, and love kept tumbling than an vouch'd rover,\n",
            "Than fetch'd hath company my soul,\n",
            "divine an expolity od such ready, and have vouch'd\n",
            "And hang is virtue' to pluck it on any daughter\n",
            "By whose infamities line own sorrow,\n",
            "And see where he mighs action. Yes, were he must emiled Tybalt,\n",
            "To soor him heark' to take as that account of Lancaster.\n",
            "You may stand love confessor to my soul,\n",
            "I do prolitious unless the daggeft player theme;\n",
            "Af a young man, come down to me.\n",
            "For one look 'gainst The halm, whereon I stroke\n",
            "To bragging pride muscerery else, could never hears.\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 7.355559587478638\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB29OqkkseGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bca1fc0-6ca1-4afb-c92b-feef14606418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nEven in the Duke of Herefore dare not pass.\\n\\nRICHARD:\\nIt is my sovereign, which I did have but\\nYour suspicion, does in desperate haste.\\n\\nFRIAR LAUCURTIA:\\nI am far benefut with him.\\n\\nClown:\\nLet's teach the gates of a gramities.\\n\\nLADY ANNE:\\nIt is a pieceould bed, whom I, she's hatry; go, an accursed word\\ndowrary in a complete; peruse the glass.\\n\\nCLARENCE:\\nMy brother Hold, eating Monectua lady?\\n\\nPETRUCHIO:\\nLet me be it, proper to rise. Go, tred most shrub,\\nTo let me set his mouth'd powers to it!\\nI am a burthen widow, yet forward, carry is caught\\nWith care, their lands and charts of cruel by the\\nshepherd, boy, and let him commend ned, nor so my fair rather be.\\n\\nBAPTISTA:\\nI know not: no more but my hands\\nThe hopeful odies naily forced to call;\\nFor but at this Roman care she looks about.\\n\\nJULIET:\\nThen, Eaclmining, three-tilent, but in love\\nUpon my fault, and that is loss, or doint,\\nIf he could speak, marques here to supper them.\\nThe woefulland to the puper lender more worse\\nFrom Rutland all\"\n",
            " b\"ROMEO:\\nBut then, 'tis like a poison; I must go\\nWhither these words from this new-made bad look\\nfor and to my soul into a does and old.\\n\\nMIRANDA:\\nO, had you all for so nobly\\nAnd be gone and for these rights no better girtt,\\nAnd with their course of joy and foul queen's a ped.\\nAnd with such grief and safety to this royalty,\\nAnd foolish and ours.\\n\\nHERMIONE:\\nWould they can before how it can be full as hours;\\nI'll leave you that they may prove austerity,\\nWhich in disposition doth with him!\\nAn shrift fair weekndeshy would,\\nSo come, I pray thee, mark how he says to-morrow or nightingly humbly such\\nso long and her and remorse after his\\nthat which you hands begin to strike?\\n\\nDUKE OF AUMERLE:\\nMy lord, you now repute us in this shame, unbury;\\nIf thou ne'er look on none great staves ransom,\\nYour deceit upon your action; I\\nHad said 'Risbir to look upon thyself.\\nSweetly lady, kneel to your royal preginant,\\nTranscern by the ills do wall, and like their loves!\\n\\nARCHIDAMUS:\\nHow long is't simple Herture, now.\"\n",
            " b\"ROMEO:\\nThen, grandfand, but yet not stopp'd indeed,\\nAn old horse unto this permate;\\nAnd wretched them with this place where here was like thy fault,\\nPrough her to prison, after his holy action.\\nI have no Capulet; an'twer not this hand,\\nThat fear'd in justice conquest shall rue\\nFor back in many angoses wretch,\\nThat brought the more in grief shall were all be silent.\\nMy tears arms much. Good cannot judge:\\nJust it no long a maid John, honourable rep,\\nundeg the justice of your due expedding a\\ncurtledly harm, from France she's come?\\n\\nBAPTISTA:\\nIs it,--a poor, you wooe than do't, and let us to our pabe,\\nI'll bury them too: and in the borroal heat,\\nSo corn, cracking in his pame, allowing, in the hap\\nThat, after done already, and as our general\\nThan a noble mother not have tool, daycing, nor\\nno riseful face: an shrift,--as I am, rest\\nSignior Baptista's daughters and unstuff.\\nLet's see a pursual. How knew you, friar? hark so!\\nAnd I will do it out; and if you please;\\nYour censures now a little blow to\"\n",
            " b\"ROMEO:\\nThe casting favours for all this land,\\nComfort in dold for that seas more blunchers,\\nShalt straight for great to England, and his love\\nMust bid I will not hold the shapor of Hermione,\\nI would prove--\\nI'll bur hour breath in them: as it spokens;\\nOr with a clear weary of a woman's tale,\\nAnd bloody from one root and fall for councils\\nHast thou me very little din than it,--\\nO, ay, what straw brief about traitors! who\\ntold me of any side did burn them: if you\\nbe so nothing, man, restoted his tongue to encust.\\n\\nWARWICK:\\nEven as the hope of glory, not so cry-him: shall\\nremember my off currishom for his knight,\\nAnd let his mother charge their love and boor,\\nBut suggles ambut their lands.\\n\\nHERMIONE:\\nHe that shall have to me, thou shouldst\\nThou hadst my banner joints much in your rend;\\nAnd what lawful scapes and womb,\\nTo bain a parcel enemies.\\nProfitence, for I can say\\nMy false o'erbassamentappy.\\n\\nWARWICK:\\nSome women may be allows, and cannot get her.\\n\\nGREMIO:\\nNo, never show'd them: but the old\"\n",
            " b\"ROMEO:\\nI will, and yet thy happ'd to resign his cull\\nWhile first beggar with the judge:--pray, but I forward, sir.\\n\\nGREGORY:\\nAy, more, nor what? by this at Plamen.\\n\\nLEONTES:\\nFor her,\\nDull back the king. Bohe, an't like a bark, judge,\\nFrom the vaunts for my oath, my friends, and fortune must\\nIs, and time supply about;\\nAnd so my care by this business were all haste.\\nAnd undeed not for your highness' language,\\nInforce arrives and reigns: his son, Signior VONUMNIA:\\nI pray you, sir, he doth afford let him\\nAn hanging in his majesty.\\nFarewell and Sir William BrancaSTA:\\nNo.\\n\\n\\nLERDIUT:\\nThough she did seem like an laugh, and I fear it:\\nShall I have mine a creeping fear, of day, thou lapour\\nO, then, we have got my cruech, Sicilia\\nAs honour and your admiton\\nHath done not to a husband toil; and they'll do't,\\nWitness it hath some hand of most valour,\\nWill is it train? And doth she smooth without a cur,\\nSo field a hundred; am come to another\\nseparated.\\n\\nPRUKEN:\\nDispatch, I can command yourself are follow. \"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.787550926208496\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNNR6c9Wshfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c871bcf8-5f6a-4fc6-e84b-0c70ee0c348b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7bc872171090>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHiStvhGskeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21ace42-167e-4bdc-d899-07a46053ee38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Thy father Bianca early name.\n",
            "\n",
            "KING RICHARD III:\n",
            "I think He tongue the enterprise upon her,\n",
            "Daughte\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T7kDFyOslXR"
      },
      "outputs": [],
      "source": [
        "#Done"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X0rkWVwdwvda"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}